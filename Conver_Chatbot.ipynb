{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5beba2e1-aff2-4fbf-a51f-7653c72a9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32f96b9-86a5-4ace-af13-578ce663d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_link = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "get_link = get_link.read()\n",
    "\n",
    "data = bs.BeautifulSoup(get_link,'lxml')\n",
    "data_paragraphs = data.find_all('p')\n",
    "\n",
    "data_text =''\n",
    "for para in data_paragraphs:\n",
    "    data_text +=para.text\n",
    "\n",
    "data_text =data_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22b32c9-afa7-42ba-8b52-c76859665c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = re.sub(r'\\[[0-9]*\\]',' ',data_text)\n",
    "data_text  =re.sub(r'\\s+',' ',data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32adf68-bb02-4990-ab4d-b4debc4580a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentences = nltk.sent_tokenize(data_text)\n",
    "data_word =nltk.word_tokenize(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db8ba406-3fe6-48fc-875f-a0f9bfe3e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def perform_lemmatization(tokens):\n",
    "    return [ wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "     \n",
    "    punctuation_removal = dict((ord(punctuation), None)  for punctuation in string.punctuation)\n",
    "    \n",
    "    def get_processed_text(document):\n",
    "        return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951e52ce-b67a-40e6-8d54-66d566eb4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_input = [\"hello\", \"good morning\", \"good evening\", \"morning\", \"evening\",\"hi\",\"whatsup\"]\n",
    "greeting_response = [\"Hello\", \"Hey hows you?\", \"*nods*\", \"hello,how you doing\", \"hey\",\"welcome,i'am good and you\"]\n",
    "def greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_input:\n",
    "            return random.choice(greeting_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efd6045b-edaa-4ed8-b6b8-cc276c7aa0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c897d659-1ad7-471c-a07f-a15d3fc2fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    " def greeting_response(user_input):\n",
    "     bot_response = ''\n",
    "     data_sentences.append(user_input)\n",
    " \n",
    "     word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text,stop_words='english')\n",
    "     all_word_vectors =word_vectorizer.fit_transform(data_sentences)\n",
    "     similar_vector_values = cosine_similarity(all_word_vectors[-1],all_word_vectors)\n",
    "     similar_sentence_number =similar_vector_values.agrsort()[0][-2]\n",
    " \n",
    "     matched_vector = similar_vector_values.flatten()\n",
    "     matched_vector.sort()\n",
    "     vector_matched = matched_vector[-2]\n",
    "     if vector_matched == 0:\n",
    "        bot_response= bot_response +\"i am sorry i could not understand you \"\n",
    "        return bot_response\n",
    "     else :\n",
    "          bot_response = bot_response+ data_sentences[similar_sentence_number]\n",
    "     return bot_response\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485cae6-fd80-4f09-a20f-c47e7ff8b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_dialog = True\n",
    " print(\"hello i am from ai sciences, you can ask me any quetion regardring Ai\")\n",
    " while(continue_dialog ==True):\n",
    "     human_text =input()\n",
    "     human_text =human_text.lower\n",
    "     if human_text !=bye:\n",
    "         if human_text =='thanks' or human_text=='thank u very much' or human_text =='thank you':\n",
    "             continue_dialog =false\n",
    "             print (\"ai sciences: most welcome\")\n",
    "         else:\n",
    "             if generate_greeting_response(human_text) !=None:\n",
    "                 print(\"ai sciences:\" +generate_greeting_response(human_text))\n",
    "             else:\n",
    "                 print(\"ai sciences:\", end=\"\")\n",
    "                 print(generate_response(human_text))\n",
    "                 data_sentences.remove(human_text)\n",
    "     else:\n",
    "         continue_dialog =False\n",
    "         print (\"ai sciences: good bye and take care of yourself......\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
